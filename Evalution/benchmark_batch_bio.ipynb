{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: SingleCellExperiment\n",
      "\n",
      "R[write to console]: Loading required package: SummarizedExperiment\n",
      "\n",
      "R[write to console]: Loading required package: MatrixGenerics\n",
      "\n",
      "R[write to console]: Loading required package: matrixStats\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘MatrixGenerics’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n",
      "    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n",
      "    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n",
      "    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n",
      "    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n",
      "    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n",
      "    colWeightedMeans, colWeightedMedians, colWeightedSds,\n",
      "    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n",
      "    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n",
      "    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n",
      "    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n",
      "    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n",
      "    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n",
      "    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n",
      "    rowWeightedSds, rowWeightedVars\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: GenomicRanges\n",
      "\n",
      "R[write to console]: Loading required package: stats4\n",
      "\n",
      "R[write to console]: Loading required package: BiocGenerics\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    Filter, Find, Map, Position, Reduce, anyDuplicated, append,\n",
      "    as.data.frame, basename, cbind, colnames, dirname, do.call,\n",
      "    duplicated, eval, evalq, get, grep, grepl, intersect, is.unsorted,\n",
      "    lapply, mapply, match, mget, order, paste, pmax, pmax.int, pmin,\n",
      "    pmin.int, rank, rbind, rownames, sapply, setdiff, sort, table,\n",
      "    tapply, union, unique, unsplit, which.max, which.min\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: S4Vectors\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    I, expand.grid, unname\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: IRanges\n",
      "\n",
      "R[write to console]: Loading required package: GenomeInfoDb\n",
      "\n",
      "R[write to console]: Loading required package: Biobase\n",
      "\n",
      "R[write to console]: Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘Biobase’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:MatrixGenerics’:\n",
      "\n",
      "    rowMedians\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/root/workspace/sjh/data/paper\")\n",
    "from os.path import join as pj\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append(\"modules\")\n",
    "import utils\n",
    "import numpy as np\n",
    "import scib\n",
    "import scib.metrics as me\n",
    "import anndata as ad\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import re\n",
    "from glob import glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, default='dm_sub10')\n",
    "# parser.add_argument('--ref_task', type=str, default='bmmc_sub100')\n",
    "parser.add_argument('--experiment', type=str, default='mask_0.3')\n",
    "parser.add_argument('--model', type=str, default='default')\n",
    "parser.add_argument('--method', type=str, default='embed')\n",
    "o, _ = parser.parse_known_args()  # for python interactive\n",
    "test_dir = \"predict\"\n",
    "# o = parser.parse_args()\n",
    "start = 999\n",
    "end = 1000\n",
    "step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_task = re.sub(\"_vd.*|_vt.*|_atlas|_generalize|_transfer|_ref_.*\", \"\", o.task)\n",
    "data_config = utils.load_toml(\"configs/data.toml\")[cfg_task]\n",
    "for k, v in data_config.items():\n",
    "    vars(o)[k] = v\n",
    "model_config = utils.load_toml(\"configs/model.toml\")[\"default\"]\n",
    "if o.model != \"default\":\n",
    "    model_config.update(utils.load_toml(\"configs/model.toml\")[o.model])\n",
    "for k, v in model_config.items():\n",
    "    vars(o)[k] = v\n",
    "o.s_joint, o.combs, *_ = utils.gen_all_batch_ids(o.s_joint, o.combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pericytes', 'Fibroblasts', 'Oligodendrocytes', 'Epithelial cells', 'Endothelial cells', 'Proliferating Erythrocytes', 'Erythrocytes', 'Ependymal cells']\n",
      "['0']\n"
     ]
    }
   ],
   "source": [
    "# Load cell type labels\n",
    "labels = []\n",
    "batch = []\n",
    "labels_dir = []\n",
    "for raw_data_dir in o.raw_data_dirs:\n",
    "    for s in o.s_joint:\n",
    "        labels_dir += glob(pj(\"/dev/shm/processed/\", o.task, \"subset_\" + str(s), \"labels.csv\"))\n",
    "        # labels_dir += glob(pj(\"/dev/shm/processed/\", o.ref_task, \"subset_\" + str(s), \"labels.csv\"))\n",
    "\n",
    "p = 0\n",
    "for l in labels_dir:\n",
    "    label = utils.load_csv(l)[1:]\n",
    "    labels += utils.transpose_list(label)[6]\n",
    "    batch += [str(p)] * len(label)\n",
    "    p += 1\n",
    "\n",
    "labels = np.array(labels)\n",
    "batch = np.array(batch)\n",
    "\n",
    "print(list(set(labels)))\n",
    "print(list(set(batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_evaluate(o, pred, labels, result_dir):\n",
    "    if o.method in [\"embed\", \"mofa\", \"scmomat\", \"stabmap\", \"scvaeit\", \"multigrate\", \"glue\"]:\n",
    "        output_type = \"embed\"\n",
    "    elif o.method in [\n",
    "        \"midas_feat+wnn\", \n",
    "        \"harmony+wnn\", \n",
    "        \"pca+wnn\",\n",
    "        \"seurat_cca+wnn\",\n",
    "        \"seurat_rpca+wnn\",\n",
    "        \"scanorama_embed+wnn\",\n",
    "        \"scanorama_feat+wnn\",\n",
    "        \"liger+wnn\",\n",
    "        \"bbknn\",\n",
    "        ]:\n",
    "        output_type = \"graph\"\n",
    "    else:\n",
    "        assert False, o.method+\": invalid method!\"\n",
    "\n",
    "    embed = \"X_emb\"\n",
    "    batch_key = \"batch\"\n",
    "    label_key = \"label\"\n",
    "    cluster_key = \"cluster\"\n",
    "    si_metric = \"euclidean\"\n",
    "    subsample = 0.5\n",
    "    verbose = False\n",
    "\n",
    "    c = pred[\"z\"][\"joint\"][:, :o.dim_c]\n",
    "    s = pred[\"s\"][\"joint\"]\n",
    "\n",
    "    if o.method == \"embed\":\n",
    "        adata = ad.AnnData(c)\n",
    "        adata.obsm[embed] = c\n",
    "        adata.obs[batch_key] = s.astype(str)\n",
    "        adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "        adata.obs[label_key] = labels\n",
    "        adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "    elif o.method in [\"mofa\", \"stabmap\", \"multigrate\", \"glue\"]:\n",
    "        adata = ad.AnnData(c*0)\n",
    "        embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "        adata.obsm[embed] = np.array(embeddings)[1:, 1:].astype(np.float32)\n",
    "        adata.obs[batch_key] = s.astype(str)\n",
    "        adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "        adata.obs[label_key] = labels\n",
    "        adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "    elif o.method in [\"scmomat\", \"scvaeit\"]:\n",
    "        adata = ad.AnnData(c*0)\n",
    "        embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "        adata.obsm[embed] = np.array(embeddings).astype(np.float32)\n",
    "        adata.obs[batch_key] = s.astype(str)\n",
    "        adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "        adata.obs[label_key] = labels\n",
    "        adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "    elif o.method in [\n",
    "        \"midas_feat+wnn\", \n",
    "        \"harmony+wnn\", \n",
    "        \"pca+wnn\",\n",
    "        \"seurat_cca+wnn\",\n",
    "        \"seurat_rpca+wnn\",\n",
    "        \"scanorama_embed+wnn\",\n",
    "        \"scanorama_feat+wnn\",\n",
    "        \"liger+wnn\",\n",
    "        \"bbknn\",\n",
    "        ]:\n",
    "        adata = ad.AnnData(c*0)\n",
    "        adata.obs[batch_key] = s.astype(str)\n",
    "        adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "        adata.obs[label_key] = labels\n",
    "        adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "        adata.obsp[\"connectivities\"] = scipy.io.mmread(pj(result_dir, \"connectivities.mtx\")).tocsr()\n",
    "        adata.uns[\"neighbors\"] = {'connectivities_key': 'connectivities'}\n",
    "\n",
    "    results = {}\n",
    "    # print(adata)\n",
    "\n",
    "    print('clustering...')\n",
    "    res_max, nmi_max, nmi_all = scib.clustering.opt_louvain(adata, label_key=label_key,\n",
    "        cluster_key=cluster_key, function=me.nmi, use_rep=embed, verbose=verbose, inplace=True)\n",
    "    \n",
    "    # results[\"asw_batch\"] = me.silhouette_batch(adata, batch_key=batch_key,\n",
    "    #         group_key=label_key, embed=embed, metric=si_metric, verbose=verbose)\n",
    "    \n",
    "    results['NMI'] = me.nmi(adata, group1=cluster_key, group2=label_key, method='arithmetic')\n",
    "    print(\"NMI: \" + str(results['NMI']))\n",
    "\n",
    "    results['ARI'] = me.ari(adata, group1=cluster_key, group2=label_key)\n",
    "    print(\"ARI: \" + str(results['ARI']))\n",
    "\n",
    "    # type_ = \"knn\" if output_type == \"graph\" else None\n",
    "    # results['kBET'] = me.kBET(adata, batch_key=batch_key, label_key=label_key, embed=embed, \n",
    "    #     type_=type_, verbose=verbose, return_df = False)\n",
    "    # print(\"kBET: \" + str(results['kBET']))\n",
    "\n",
    "    results['il_score_asw'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "        embed=embed, cluster=False, verbose=verbose)\n",
    "    print(\"il_score_asw: \" + str(results['il_score_asw']))\n",
    "\n",
    "    # results['graph_conn'] = me.graph_connectivity(adata, label_key=label_key)\n",
    "    # print(\"graph_conn: \" + str(results['graph_conn']))\n",
    "\n",
    "    # results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "    #     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "    # print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "    # results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "    #     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "    # print(\"iLISI: \" + str(results['iLISI']))\n",
    "\n",
    "    results = {k: float(v) for k, v in results.items()}\n",
    "    # results['batch_score'] = np.nanmean([results['iLISI'], results['graph_conn'], results['kBET']])\n",
    "    results['bio_score'] = np.nanmean([results['NMI'], results['ARI'], results['il_score_asw']])\n",
    "    # results[\"overall_score\"] = float(0.4 * results['batch_score'] + 0.6 * results['bio_score'])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        # 'iLISI':          [results['iLISI']],\n",
    "        # 'graph_conn':     [results['graph_conn']],\n",
    "        # 'kBET':           [results['kBET']],\n",
    "        # # 'asw_batch':      [results['asw_batch']],\n",
    "        # 'batch_score':    [results['batch_score']],\n",
    "        'NMI':            [results['NMI']],\n",
    "        'ARI':            [results['ARI']],\n",
    "        'il_score_asw':    [results['il_score_asw']],\n",
    "        # 'cLISI':          [results['cLISI']],\n",
    "        'bio_score':      [results['bio_score']],\n",
    "        # 'overall_score':  [results['overall_score']]\n",
    "    })\n",
    "    print(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predicted variables ...\n",
      "Converting to numpy ...\n",
      "clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/private/lib/python3.8/site-packages/umap/distances.py:1051: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/root/anaconda3/envs/private/lib/python3.8/site-packages/umap/distances.py:1059: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/root/anaconda3/envs/private/lib/python3.8/site-packages/umap/distances.py:1074: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/root/anaconda3/envs/private/lib/python3.8/site-packages/pynndescent/utils.py:202: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit(\n",
      "/root/anaconda3/envs/private/lib/python3.8/site-packages/pynndescent/utils.py:302: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit(\n",
      "/root/anaconda3/envs/private/lib/python3.8/site-packages/umap/umap_.py:673: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.7452647768780244\n",
      "ARI: 0.8213679684478459\n",
      "il_score_asw: 0.6255591651424766\n",
      "        NMI       ARI  il_score_asw  bio_score\n",
      "0  0.745265  0.821368      0.625559   0.730731\n"
     ]
    }
   ],
   "source": [
    "o.mods = [\"rna\", \"adt\"]\n",
    "df_batch_bio_embed = []\n",
    "\n",
    "for i in list(range(start, end, step)):\n",
    "    init_model = \"sp_0000{:04d}\".format(i)\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.experiment)\n",
    "    utils.mkdirs(result_dir, remove_old = False)\n",
    "    # Load predicted latent variables\n",
    "    o.pred_dir = pj(\"result\", o.task, o.experiment, o.model, test_dir, init_model)\n",
    "    pred = utils.load_predicted(o)\n",
    "    df_bio = bio_evaluate(o, pred, labels, result_dir)\n",
    "    df_bio[\"Model\"] = \"Step_\" + \"{:04d}\".format(i + 1)\n",
    "    df_batch_bio_embed.append(df_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SLN\n",
    "# df_bio_cat = pd.concat(df_batch_bio_embed, axis = 0)\n",
    "# df_bio_mean_cat = copy.deepcopy(df_bio_cat)\n",
    "# # df_bio_mean_cat[\"batch_score\"] = df_bio_cat[[\"iLISI\", \"graph_conn\", \"kBET\", \"asw_batch\"]].mean(axis = 1)\n",
    "# df_bio_mean_cat[\"batch_score\"] = df_bio_cat[[\"iLISI\", \"graph_conn\", \"kBET\"]].mean(axis = 1)\n",
    "# df_bio_mean_cat[\"bio_score\"] = df_bio_cat[[\"NMI\", \"ARI\", \"il_score_asw\", \"cLISI\"]].mean(axis = 1)\n",
    "# df_bio_mean_cat = df_bio_mean_cat[[\"Model\", \"NMI\", \"ARI\", \"il_score_asw\", \"cLISI\", \"bio_score\", \"iLISI\", \"graph_conn\", \"kBET\", \"batch_score\"]]\n",
    "# # df_bio_mean_cat = df_bio_mean_cat[[\"Model\", \"NMI\", \"ARI\", \"il_score_asw\", \"cLISI\", \"bio_score\", \"iLISI\", \"graph_conn\", \"kBET\", \"asw_batch\", \"batch_score\"]]\n",
    "# # df_bio_mean_cat_sorted = df_bio_mean_cat.sort_values(\"bio_score\", ascending = False, inplace = False)\n",
    "# df_bio_mean_cat.to_csv(pj(result_dir, \"metrics_bio_train.csv\"), index = False)\n",
    "# df_bio_mean_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>NMI</th>\n",
       "      <th>ARI</th>\n",
       "      <th>il_score_asw</th>\n",
       "      <th>bio_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step_1000</td>\n",
       "      <td>0.745265</td>\n",
       "      <td>0.821368</td>\n",
       "      <td>0.625559</td>\n",
       "      <td>0.730731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model       NMI       ARI  il_score_asw  bio_score\n",
       "0  Step_1000  0.745265  0.821368      0.625559   0.730731"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DM\n",
    "df_bio_cat = pd.concat(df_batch_bio_embed, axis = 0)\n",
    "df_bio_mean_cat = copy.deepcopy(df_bio_cat)\n",
    "df_bio_mean_cat[\"bio_score\"] = df_bio_cat[[\"NMI\", \"ARI\", \"il_score_asw\"]].mean(axis = 1)\n",
    "df_bio_mean_cat = df_bio_mean_cat[[\"Model\", \"NMI\", \"ARI\", \"il_score_asw\", \"bio_score\"]]\n",
    "# df_bio_mean_cat_sorted = df_bio_mean_cat.sort_values(\"bio_score\", ascending = False, inplace = False)\n",
    "# df_bio_mean_cat.to_csv(pj(result_dir, \"metrics_bio_train.csv\"), index = False)\n",
    "df_bio_mean_cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "private",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
